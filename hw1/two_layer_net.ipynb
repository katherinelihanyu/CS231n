{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Neural Network\n",
    "In this exercise we will develop a neural network with fully-connected layers to perform classification, and test it out on the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit of setup\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cs231n.classifiers.neural_net import TwoLayerNet\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the class `TwoLayerNet` in the file `cs231n/classifiers/neural_net.py` to represent instances of our network. The network parameters are stored in the instance variable `self.params` where keys are string parameter names and values are numpy arrays. Below, we initialize toy data and a toy model that we will use to develop your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small net and some toy data to check your implementations.\n",
    "# Note that we set the random seed for repeatable experiments.\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model():\n",
    "    np.random.seed(0)\n",
    "    return TwoLayerNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def init_toy_data():\n",
    "    np.random.seed(1)\n",
    "    X = 10 * np.random.randn(num_inputs, input_size)\n",
    "    y = np.array([0, 1, 2, 2, 1])\n",
    "    return X, y\n",
    "\n",
    "net = init_toy_model()\n",
    "X, y = init_toy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass: compute scores\n",
    "Open the file `cs231n/classifiers/neural_net.py` and look at the method `TwoLayerNet.loss`. This function is very similar to the loss functions you have written for the SVM and Softmax exercises: It takes the data and weights and computes the class scores, the loss, and the gradients on the parameters. \n",
    "\n",
    "Implement the first part of the forward pass which uses the weights and biases to compute the scores for all inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your scores:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "correct scores:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "Difference between your scores and correct scores:\n",
      "3.6802720496109664e-08\n"
     ]
    }
   ],
   "source": [
    "scores = net.loss(X)\n",
    "print('Your scores:')\n",
    "print(scores)\n",
    "print()\n",
    "print('correct scores:')\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "print(correct_scores)\n",
    "print()\n",
    "\n",
    "# The difference should be very small. We get < 1e-7\n",
    "print('Difference between your scores and correct scores:')\n",
    "print(np.sum(np.abs(scores - correct_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass: compute loss\n",
    "In the same function, implement the second part that computes the data and regularizaion loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between your loss and correct loss:\n",
      "1.7985612998927536e-13\n"
     ]
    }
   ],
   "source": [
    "loss, _ = net.loss(X, y, reg=0.05)\n",
    "correct_loss = 1.30378789133\n",
    "\n",
    "# should be very small, we get < 1e-12\n",
    "print('Difference between your loss and correct loss:')\n",
    "print(np.sum(np.abs(loss - correct_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward pass\n",
    "Implement the rest of the function. This will compute the gradient of the loss with respect to the variables `W1`, `b1`, `W2`, and `b2`. Now that you (hopefully!) have a correctly implemented forward pass, you can debug your backward pass using a numeric gradient check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704838 -0.03069197  0.00636804  0.00174577  0.00085368 -0.00268097\n",
      "   0.00093444 -0.0131879  -0.01734729 -0.00961751]\n",
      " [ 0.0015209   0.02392258 -0.03615624  0.01552418  0.01448697  0.00510457\n",
      "  -0.00476489 -0.00210967 -0.00313314  0.01979224]\n",
      " [ 0.00715901  0.02018676  0.01562179 -0.01187166 -0.0101846  -0.00015141\n",
      "   0.00194897  0.016542    0.02198668 -0.0014834 ]\n",
      " [ 0.00717792  0.01944022  0.01727122 -0.0126382  -0.01088983 -0.00036107\n",
      "   0.0021651   0.01681481  0.02236269 -0.00230647]\n",
      " [ 0.00090184  0.01832638 -0.02976535  0.01301156  0.01210218  0.00411025\n",
      "  -0.00391774 -0.00243716 -0.00350387  0.01597709]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704843 -0.03069219  0.00636808  0.00174578  0.00085369 -0.00268099\n",
      "   0.00093445 -0.01318799 -0.01734742 -0.00961758]\n",
      " [ 0.00152085  0.02392234 -0.0361562   0.01552419  0.01448698  0.00510455\n",
      "  -0.00476489 -0.00210978 -0.00313328  0.01979217]\n",
      " [ 0.00715896  0.02018652  0.01562187 -0.01187166 -0.0101846  -0.00015143\n",
      "   0.00194898  0.01654191  0.02198656 -0.00148348]\n",
      " [ 0.00717787  0.01943998  0.01727131 -0.01263821 -0.01088984 -0.00036109\n",
      "   0.00216511  0.01681472  0.02236258 -0.00230655]\n",
      " [ 0.00090179  0.01832616 -0.02976527  0.01301156  0.01210217  0.00411023\n",
      "  -0.00391773 -0.00243724 -0.00350398  0.01597701]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069212  0.00636814  0.00174574  0.00085365 -0.00268099\n",
      "   0.00093445 -0.01318794 -0.01734735 -0.00961759]\n",
      " [ 0.00152087  0.02392242 -0.03615616  0.01552416  0.01448695  0.00510455\n",
      "  -0.00476488 -0.00210972 -0.0031332   0.01979217]\n",
      " [ 0.00715898  0.02018658  0.01562191 -0.01187169 -0.01018464 -0.00015143\n",
      "   0.00194899  0.01654196  0.02198663 -0.00148349]\n",
      " [ 0.00717789  0.01944004  0.01727136 -0.01263824 -0.01088987 -0.0003611\n",
      "   0.00216512  0.01681477  0.02236264 -0.00230656]\n",
      " [ 0.00090181  0.01832621 -0.02976521  0.01301152  0.01210213  0.00411023\n",
      "  -0.00391772 -0.00243719 -0.00350392  0.015977  ]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069204  0.00636798  0.00174581  0.00085372 -0.00268097\n",
      "   0.00093443 -0.01318796 -0.01734737 -0.0096175 ]\n",
      " [ 0.00152088  0.0239225  -0.03615628  0.01552421  0.014487    0.00510457\n",
      "  -0.0047649  -0.00210973 -0.00313321  0.01979224]\n",
      " [ 0.00715899  0.0201867   0.01562175 -0.01187162 -0.01018457 -0.00015141\n",
      "   0.00194896  0.01654195  0.02198661 -0.00148339]\n",
      " [ 0.0071779   0.01944016  0.01727118 -0.01263816 -0.0108898  -0.00036107\n",
      "   0.0021651   0.01681476  0.02236263 -0.00230646]\n",
      " [ 0.00090182  0.01832633 -0.0297654   0.0130116   0.01210221  0.00411026\n",
      "  -0.00391775 -0.00243721 -0.00350394  0.0159771 ]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704843 -0.03069215  0.006368    0.00174582  0.00085372 -0.00268098\n",
      "   0.00093444 -0.013188   -0.01734743 -0.00961754]\n",
      " [ 0.00152085  0.02392238 -0.03615626  0.01552422  0.01448701  0.00510456\n",
      "  -0.0047649  -0.00210978 -0.00313328  0.0197922 ]\n",
      " [ 0.00715896  0.02018658  0.01562178 -0.01187162 -0.01018457 -0.00015142\n",
      "   0.00194897  0.0165419   0.02198655 -0.00148343]\n",
      " [ 0.00717788  0.01944005  0.01727122 -0.01263817 -0.0108898  -0.00036108\n",
      "   0.0021651   0.01681472  0.02236257 -0.0023065 ]\n",
      " [ 0.00090179  0.01832621 -0.02976536  0.0130116   0.01210221  0.00411024\n",
      "  -0.00391774 -0.00243725 -0.003504    0.01597706]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704838 -0.03069201  0.00636811  0.00174573  0.00085365 -0.00268098\n",
      "   0.00093445 -0.01318789 -0.01734728 -0.00961755]\n",
      " [ 0.0015209   0.02392254 -0.03615618  0.01552415  0.01448695  0.00510456\n",
      "  -0.00476489 -0.00210967 -0.00313313  0.01979221]\n",
      " [ 0.00715901  0.0201867   0.01562188 -0.01187169 -0.01018463 -0.00015142\n",
      "   0.00194898  0.016542    0.02198669 -0.00148344]\n",
      " [ 0.00717792  0.01944016  0.01727132 -0.01263824 -0.01088987 -0.00036108\n",
      "   0.00216512  0.01681481  0.0223627  -0.00230652]\n",
      " [ 0.00090183  0.01832632 -0.02976525  0.01301152  0.01210214  0.00411024\n",
      "  -0.00391773 -0.00243715 -0.00350386  0.01597704]]\n",
      "b2 max relative error: 1.000000e+00\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704957 -0.03069164  0.00636797  0.00174575  0.00085367 -0.00268094\n",
      "   0.00093443 -0.01318776 -0.01734711 -0.00961741]\n",
      " [ 0.00152183  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715985  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.00717873  0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090254  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704723 -0.03069252  0.00636815  0.0017458   0.0008537  -0.00268102\n",
      "   0.00093446 -0.01318814 -0.01734761 -0.00961768]\n",
      " [ 0.00151992  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715813  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.00717707  0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090109  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704795 -0.03069225  0.00636837  0.00174564  0.00085356 -0.00268102\n",
      "   0.00093449 -0.01318791 -0.01734731 -0.00961771]\n",
      " [ 0.00151922  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715951  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071785   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090046  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704886 -0.03069191  0.00636775  0.00174591  0.00085382 -0.00268094\n",
      "   0.0009344  -0.01318798 -0.01734741 -0.00961738]\n",
      " [ 0.00152253  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715846  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071773   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090317  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704769 -0.03069235  0.00636784  0.00174594  0.00085383 -0.00268098\n",
      "   0.00093442 -0.01318817 -0.01734766 -0.00961752]\n",
      " [ 0.00152158  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.0071576   0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.00717647  0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090244  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704912 -0.0306918   0.00636828  0.00174561  0.00085354 -0.00268098\n",
      "   0.00093447 -0.01318772 -0.01734706 -0.00961757]\n",
      " [ 0.00152017  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00716037  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.00717933  0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090119  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069335  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392341 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.0201875   0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.01944093  0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832699 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069081  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392151 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018578  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.01943927  0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832554 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069162  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.0239208  -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018716  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194407   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832491 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069254  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392411 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018612  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.01943951  0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832762 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069127  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392316 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018526  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.01943867  0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.0183269  -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069289  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392175 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018802  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.01944153  0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832564 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704836 -0.0306919   0.00636675  0.00174576  0.00085368 -0.00268096\n",
      "   0.00093444 -0.01318787 -0.01734726 -0.00961749]\n",
      " [ 0.00152091  0.02392261 -0.0361553   0.01552417  0.01448697  0.00510457\n",
      "  -0.00476489 -0.00210965 -0.00313312  0.01979225]\n",
      " [ 0.00715907  0.02018702  0.01562257 -0.01187166 -0.01018459 -0.00015138\n",
      "   0.00194896  0.0165421   0.02198682 -0.0014833 ]\n",
      " [ 0.00717793  0.01944026  0.01727204 -0.0126382  -0.01088983 -0.00036107\n",
      "   0.0021651   0.01681482  0.02236271 -0.00230645]\n",
      " [ 0.00090181  0.01832627 -0.02976458  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704845 -0.03069226  0.00636937  0.00174579  0.00085369 -0.002681\n",
      "   0.00093445 -0.01318802 -0.01734746 -0.0096176 ]\n",
      " [ 0.00152084  0.0239223  -0.03615714  0.0155242   0.01448698  0.00510454\n",
      "  -0.00476489 -0.00210979 -0.0031333   0.01979216]\n",
      " [ 0.0071589   0.02018626  0.01562109 -0.01187166 -0.01018461 -0.00015146\n",
      "   0.00194899  0.0165418   0.02198642 -0.00148357]\n",
      " [ 0.00717787  0.01943994  0.01727049 -0.01263821 -0.01088984 -0.0003611\n",
      "   0.00216512  0.01681471  0.02236256 -0.00230657]\n",
      " [ 0.00090181  0.01832627 -0.02976603  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069215  0.00636864  0.00174572  0.00085363 -0.002681\n",
      "   0.00093446 -0.01318793 -0.01734734 -0.00961761]\n",
      " [ 0.00152087  0.02392241 -0.0361578   0.01552415  0.01448695  0.00510455\n",
      "  -0.00476488 -0.00210972 -0.0031332   0.01979216]\n",
      " [ 0.00715897  0.02018646  0.01562262 -0.01187177 -0.01018471 -0.00015146\n",
      "   0.00194901  0.01654197  0.02198664 -0.00148359]\n",
      " [ 0.00717789  0.01944002  0.01727199 -0.01263826 -0.01088988 -0.0003611\n",
      "   0.00216513  0.01681477  0.02236264 -0.00230658]\n",
      " [ 0.00090181  0.01832627 -0.02976666  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069201  0.00636747  0.00174583  0.00085374 -0.00268096\n",
      "   0.00093443 -0.01318796 -0.01734738 -0.00961748]\n",
      " [ 0.00152088  0.02392251 -0.03615464  0.01552422  0.01448701  0.00510457\n",
      "  -0.0047649  -0.00210973 -0.00313322  0.01979225]\n",
      " [ 0.007159    0.02018682  0.01562104 -0.01187154 -0.01018449 -0.00015138\n",
      "   0.00194894  0.01654194  0.0219866  -0.00148329]\n",
      " [ 0.00717791  0.01944019  0.01727055 -0.01263815 -0.01088979 -0.00036107\n",
      "   0.00216509  0.01681476  0.02236263 -0.00230644]\n",
      " [ 0.00090181  0.01832627 -0.02976395  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704844 -0.03069219  0.00636878  0.00174584  0.00085374 -0.00268098\n",
      "   0.00093443 -0.01318804 -0.01734748 -0.00961754]\n",
      " [ 0.00152084  0.02392236 -0.03615557  0.01552423  0.01448702  0.00510455\n",
      "  -0.0047649  -0.0021098  -0.00313331  0.0197922 ]\n",
      " [ 0.00715892  0.02018644  0.01562029 -0.01187154 -0.0101845  -0.00015142\n",
      "   0.00194896  0.01654179  0.0219864  -0.00148342]\n",
      " [ 0.00717787  0.01944003  0.01726977 -0.01263815 -0.01088979 -0.00036108\n",
      "   0.0021651   0.0168147   0.02236255 -0.0023065 ]\n",
      " [ 0.00090181  0.01832627 -0.02976468  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704836 -0.03069197  0.00636734  0.00174571  0.00085363 -0.00268098\n",
      "   0.00093446 -0.01318785 -0.01734723 -0.00961755]\n",
      " [ 0.00152091  0.02392256 -0.03615687  0.01552414  0.01448694  0.00510456\n",
      "  -0.00476488 -0.00210965 -0.00313311  0.01979221]\n",
      " [ 0.00715906  0.02018684  0.01562337 -0.01187177 -0.0101847  -0.00015142\n",
      "   0.001949    0.01654212  0.02198684 -0.00148345]\n",
      " [ 0.00717793  0.01944018  0.01727276 -0.01263825 -0.01088988 -0.00036108\n",
      "   0.00216512  0.01681483  0.02236272 -0.00230652]\n",
      " [ 0.00090181  0.01832627 -0.02976593  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704825 -0.0306914   0.00636792  0.00174447  0.00085367 -0.00268092\n",
      "   0.00093442 -0.01318765 -0.01734697 -0.00961733]\n",
      " [ 0.00152093  0.02392268 -0.03615626  0.01552512  0.01448697  0.00510458\n",
      "  -0.0047649  -0.00210962 -0.00313308  0.01979227]\n",
      " [ 0.00715908  0.02018708  0.0156217  -0.0118708  -0.01018459 -0.00015138\n",
      "   0.00194896  0.01654212  0.02198684 -0.00148329]\n",
      " [ 0.00717791  0.01944017  0.01727124 -0.01263737 -0.01088983 -0.00036108\n",
      "   0.00216511  0.01681479  0.02236267 -0.00230648]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301229  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704856 -0.03069276  0.0063682   0.00174708  0.0008537  -0.00268104\n",
      "   0.00093447 -0.01318824 -0.01734774 -0.00961776]\n",
      " [ 0.00152082  0.02392223 -0.03615618  0.01552325  0.01448699  0.00510454\n",
      "  -0.00476488 -0.00210982 -0.00313334  0.01979214]\n",
      " [ 0.00715889  0.0201862   0.01562196 -0.01187252 -0.01018461 -0.00015146\n",
      "   0.00194899  0.01654178  0.0219864  -0.00148359]\n",
      " [ 0.00717789  0.01944003  0.01727129 -0.01263904 -0.01088984 -0.00036109\n",
      "   0.00216511  0.01681474  0.0223626  -0.00230653]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301083  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069234  0.00636854  0.00174602  0.00085349 -0.00268104\n",
      "   0.00093451 -0.01318789 -0.01734728 -0.00961779]\n",
      " [ 0.00152087  0.02392238 -0.0361561   0.01552248  0.01448693  0.00510454\n",
      "  -0.00476487 -0.00210972 -0.0031332   0.01979214]\n",
      " [ 0.00715897  0.02018643  0.01562214 -0.01187127 -0.01018473 -0.00015146\n",
      "   0.00194902  0.01654197  0.02198665 -0.00148361]\n",
      " [ 0.0071779   0.01944007  0.01727132 -0.01263763 -0.01088986 -0.00036109\n",
      "   0.00216512  0.01681477  0.02236264 -0.00230654]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301021  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069182  0.00636758  0.00174553  0.00085388 -0.00268092\n",
      "   0.00093438 -0.013188   -0.01734744 -0.0096173 ]\n",
      " [ 0.00152088  0.02392253 -0.03615634  0.01552589  0.01448703  0.00510457\n",
      "  -0.00476491 -0.00210973 -0.00313322  0.01979227]\n",
      " [ 0.007159    0.02018685  0.01562152 -0.01187205 -0.01018448 -0.00015137\n",
      "   0.00194894  0.01654193  0.0219866  -0.00148327]\n",
      " [ 0.0071779   0.01944014  0.01727121 -0.01263878 -0.01088982 -0.00036108\n",
      "   0.0021651   0.01681476  0.02236263 -0.00230648]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301291  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704856 -0.0306925   0.00636772  0.00174684  0.0008539  -0.00268098\n",
      "   0.0009344  -0.0131883  -0.01734782 -0.00961751]\n",
      " [ 0.00152083  0.02392231 -0.0361563   0.01552496  0.01448703  0.00510455\n",
      "  -0.0047649  -0.00210983 -0.00313335  0.0197922 ]\n",
      " [ 0.00715891  0.02018641  0.01562165 -0.01187291 -0.01018449 -0.00015142\n",
      "   0.00194895  0.01654176  0.02198637 -0.00148342]\n",
      " [ 0.00717789  0.01944007  0.01727124 -0.01263961 -0.01088982 -0.00036108\n",
      "   0.00216511  0.01681474  0.0223626  -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301219  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704825 -0.03069166  0.00636839  0.00174471  0.00085347 -0.00268098\n",
      "   0.00093449 -0.0131876  -0.01734689 -0.00961758]\n",
      " [ 0.00152092  0.02392261 -0.03615614  0.01552342  0.01448692  0.00510456\n",
      "  -0.00476488 -0.00210962 -0.00313307  0.01979221]\n",
      " [ 0.00715907  0.02018687  0.01562201 -0.01187041 -0.01018472 -0.00015142\n",
      "   0.001949    0.01654214  0.02198687 -0.00148346]\n",
      " [ 0.00717791  0.01944013  0.01727129 -0.0126368  -0.01088985 -0.00036108\n",
      "   0.00216511  0.01681479  0.02236267 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301093  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704835 -0.03069186  0.00636801  0.00174576  0.00085241 -0.00268096\n",
      "   0.00093444 -0.01318785 -0.01734724 -0.00961748]\n",
      " [ 0.00152101  0.02392304 -0.03615632  0.01552414  0.01448791  0.00510461\n",
      "  -0.00476491 -0.00210947 -0.00313287  0.01979238]\n",
      " [ 0.0071591   0.02018718  0.01562167 -0.01187166 -0.01018373 -0.00015137\n",
      "   0.00194895  0.01654216  0.0219869  -0.00148325]\n",
      " [ 0.00717795  0.01944036  0.01727118 -0.0126382  -0.01088899 -0.00036106\n",
      "   0.0021651   0.01681486  0.02236276 -0.00230641]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.0121029   0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704845 -0.03069229  0.0063681   0.00174579  0.00085496 -0.002681\n",
      "   0.00093445 -0.01318804 -0.01734748 -0.00961761]\n",
      " [ 0.00152074  0.02392188 -0.03615612  0.01552423  0.01448605  0.00510451\n",
      "  -0.00476487 -0.00210998 -0.00313355  0.01979203]\n",
      " [ 0.00715887  0.0201861   0.01562199 -0.01187165 -0.01018547 -0.00015147\n",
      "   0.001949    0.01654174  0.02198634 -0.00148363]\n",
      " [ 0.00717784  0.01943984  0.01727136 -0.01263821 -0.01089068 -0.00036111\n",
      "   0.00216512  0.01681467  0.02236251 -0.0023066 ]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210145  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069216  0.00636821  0.00174571  0.00085408 -0.002681\n",
      "   0.00093446 -0.01318793 -0.01734733 -0.00961762]\n",
      " [ 0.00152086  0.02392226 -0.03615592  0.01552406  0.0144852   0.00510451\n",
      "  -0.00476485 -0.00210971 -0.00313318  0.01979204]\n",
      " [ 0.00715897  0.02018638  0.01562221 -0.01187182 -0.01018423 -0.00015147\n",
      "   0.00194903  0.01654197  0.02198665 -0.00148365]\n",
      " [ 0.00717789  0.01943997  0.01727147 -0.01263829 -0.01088932 -0.00036111\n",
      "   0.00216514  0.01681477  0.02236265 -0.00230662]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210082  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.030692    0.00636791  0.00174584  0.00085329 -0.00268096\n",
      "   0.00093442 -0.01318796 -0.01734738 -0.00961747]\n",
      " [ 0.00152089  0.02392266 -0.03615652  0.01552431  0.01448875  0.0051046\n",
      "  -0.00476493 -0.00210974 -0.00313323  0.01979237]\n",
      " [ 0.007159    0.0201869   0.01562145 -0.01187149 -0.01018497 -0.00015136\n",
      "   0.00194893  0.01654193  0.02198659 -0.00148323]\n",
      " [ 0.00717791  0.01944024  0.01727107 -0.01263812 -0.01089035 -0.00036105\n",
      "   0.00216508  0.01681475  0.02236262 -0.0023064 ]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210353  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704845 -0.03069221  0.00636795  0.00174586  0.00085457 -0.00268098\n",
      "   0.00093443 -0.01318806 -0.01734751 -0.00961753]\n",
      " [ 0.00152075  0.02392208 -0.03615642  0.01552436  0.01448783  0.00510455\n",
      "  -0.00476491 -0.00211    -0.00313357  0.01979219]\n",
      " [ 0.00715889  0.02018636  0.01562161 -0.01187149 -0.01018584 -0.00015142\n",
      "   0.00194895  0.01654172  0.02198631 -0.00148342]\n",
      " [ 0.00717785  0.01943998  0.01727116 -0.01263812 -0.0108912  -0.00036108\n",
      "   0.0021651   0.01681466  0.02236249 -0.00230649]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.0121028   0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704836 -0.03069194  0.00636817  0.00174569  0.0008528  -0.00268098\n",
      "   0.00093446 -0.01318783 -0.01734721 -0.00961756]\n",
      " [ 0.001521    0.02392284 -0.03615602  0.01552401  0.01448613  0.00510456\n",
      "  -0.00476487 -0.00210945 -0.00313285  0.01979221]\n",
      " [ 0.00715909  0.02018692  0.01562205 -0.01187182 -0.01018336 -0.00015142\n",
      "   0.001949    0.01654218  0.02198693 -0.00148346]\n",
      " [ 0.00717794  0.01944022  0.01727137 -0.01263828 -0.01088848 -0.00036109\n",
      "   0.00216512  0.01681487  0.02236277 -0.00230652]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210154  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268225\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510551\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015056\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036025\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411097\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00267971\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.0051036\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015228\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036191\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00410952\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268052\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.0051029\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.0001509\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036049\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00410889\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268144\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510621\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015194\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036168\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.0041116\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268017\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510526\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.0001528\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036251\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411087\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268179\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510385\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015003\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00035965\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00410961\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093317 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476394 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194984  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216594  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391701 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093572 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476584 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194812  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216428  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391846 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.0009349  -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476655 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.0019495   0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216571  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391909 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093399 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476323 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194845  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216451  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391638 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093526 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476419 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194759  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216368  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391711 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093363 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476559 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00195036  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216654  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391837 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318922 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210877 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654281  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.0168156   0.02236263 -0.00230651]\n",
      " [ 0.00090183  0.01832637 -0.02976534  0.01301156  0.01210218  0.00411025\n",
      "  -0.00391774 -0.00243643 -0.00350388  0.01597709]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318667 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00211067 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654109  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681393  0.02236263 -0.00230651]\n",
      " [ 0.00090179  0.01832617 -0.02976527  0.01301156  0.01210217  0.00411023\n",
      "  -0.00391773 -0.00243796 -0.00350398  0.01597702]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318749 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00211138 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654247  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681536  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832621 -0.02976522  0.01301152  0.01210214  0.00411023\n",
      "  -0.00391773 -0.00243854 -0.00350392  0.01597701]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.0131884  -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210807 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654143  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681417  0.02236263 -0.00230651]\n",
      " [ 0.00090182  0.01832632 -0.02976539  0.0130116   0.01210221  0.00411025\n",
      "  -0.00391775 -0.00243585 -0.00350394  0.0159771 ]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318713 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210902 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654057  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681334  0.02236263 -0.00230651]\n",
      " [ 0.00090179  0.01832622 -0.02976536  0.0130116   0.0121022   0.00411024\n",
      "  -0.00391774 -0.00243661 -0.00350399  0.01597706]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318876 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00211043 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654334  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681619  0.02236263 -0.00230651]\n",
      " [ 0.00090183  0.01832632 -0.02976526  0.01301152  0.01210214  0.00411024\n",
      "  -0.00391773 -0.00243778 -0.00350387  0.01597704]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734863 -0.00961755]\n",
      " [ 0.00152093  0.02392272 -0.03615627  0.01552417  0.01448697  0.00510458\n",
      "  -0.0047649  -0.00210961 -0.00313211  0.01979228]\n",
      " [ 0.00715906  0.02018699  0.01562172 -0.01187166 -0.0101846  -0.00015138\n",
      "   0.00194896  0.01654209  0.02198766 -0.00148332]\n",
      " [ 0.00717795  0.01944035  0.01727118 -0.0126382  -0.01088983 -0.00036106\n",
      "   0.0021651   0.01681486  0.02236358 -0.00230642]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.0035032   0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734609 -0.00961755]\n",
      " [ 0.00152081  0.0239222  -0.03615617  0.01552421  0.01448699  0.00510453\n",
      "  -0.00476488 -0.00210984 -0.00313431  0.01979213]\n",
      " [ 0.00715891  0.02018629  0.01562194 -0.01187166 -0.01018461 -0.00015145\n",
      "   0.00194899  0.01654182  0.02198558 -0.00148356]\n",
      " [ 0.00717785  0.01943986  0.01727135 -0.01263821 -0.01088985 -0.00036111\n",
      "   0.00216512  0.01681467  0.02236168 -0.0023066 ]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350466  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.0173469  -0.00961755]\n",
      " [ 0.00152087  0.02392237 -0.03615609  0.01552413  0.01448692  0.00510454\n",
      "  -0.00476487 -0.00210971 -0.00313485  0.01979213]\n",
      " [ 0.00715898  0.02018647  0.01562208 -0.01187176 -0.0101847  -0.00015145\n",
      "   0.00194901  0.01654196  0.02198716 -0.00148357]\n",
      " [ 0.00717789  0.01943997  0.01727146 -0.01263828 -0.01088991 -0.00036111\n",
      "   0.00216513  0.01681477  0.02236324 -0.00230661]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350528  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734782 -0.00961755]\n",
      " [ 0.00152088  0.02392255 -0.03615635  0.01552424  0.01448703  0.00510458\n",
      "  -0.00476491 -0.00210973 -0.00313156  0.01979228]\n",
      " [ 0.007159    0.02018681  0.01562158 -0.01187155 -0.0101845  -0.00015138\n",
      "   0.00194894  0.01654194  0.02198608 -0.0014833 ]\n",
      " [ 0.00717791  0.01944023  0.01727108 -0.01263812 -0.01088976 -0.00036106\n",
      "   0.00216508  0.01681476  0.02236202 -0.0023064 ]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350257  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734655 -0.00961755]\n",
      " [ 0.00152082  0.02392229 -0.03615631  0.01552426  0.01448704  0.00510455\n",
      "  -0.0047649  -0.00210985 -0.00313267  0.0197922 ]\n",
      " [ 0.00715892  0.02018646  0.01562169 -0.01187155 -0.01018451 -0.00015142\n",
      "   0.00194896  0.0165418   0.02198504 -0.00148343]\n",
      " [ 0.00717786  0.01943999  0.01727116 -0.01263813 -0.01088977 -0.00036108\n",
      "   0.0021651   0.01681466  0.02236107 -0.0023065 ]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.0035033   0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734817 -0.00961755]\n",
      " [ 0.00152093  0.02392263 -0.03615613  0.01552411  0.01448691  0.00510456\n",
      "  -0.00476488 -0.0021096  -0.00313375  0.01979221]\n",
      " [ 0.00715905  0.02018682  0.01562197 -0.01187176 -0.01018469 -0.00015142\n",
      "   0.00194899  0.0165421   0.0219882  -0.00148345]\n",
      " [ 0.00717794  0.01944022  0.01727137 -0.01263828 -0.0108899  -0.00036109\n",
      "   0.00216512  0.01681486  0.0223642  -0.00230652]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350456  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704839 -0.030692    0.00636804  0.00174577  0.00085368 -0.00268097\n",
      "   0.00093444 -0.01318791 -0.01734731 -0.00961879]\n",
      " [ 0.00152102  0.02392307 -0.03615633  0.01552414  0.01448695  0.00510461\n",
      "  -0.00476491 -0.00210945 -0.00313285  0.01979334]\n",
      " [ 0.00715907  0.02018701  0.01562172 -0.01187166 -0.0101846  -0.00015138\n",
      "   0.00194896  0.0165421   0.02198681 -0.00148245]\n",
      " [ 0.00717795  0.01944036  0.01727117 -0.0126382  -0.01088982 -0.00036106\n",
      "   0.0021651   0.01681486  0.02236276 -0.00230558]\n",
      " [ 0.00090183  0.01832633 -0.02976533  0.01301156  0.01210218  0.00411025\n",
      "  -0.00391774 -0.00243717 -0.0035039   0.0159778 ]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704842 -0.03069216  0.00636808  0.00174578  0.00085369 -0.00268099\n",
      "   0.00093445 -0.01318798 -0.0173474  -0.0096163 ]\n",
      " [ 0.00152073  0.02392184 -0.03615611  0.01552423  0.014487    0.0051045\n",
      "  -0.00476487 -0.00211    -0.00313357  0.01979107]\n",
      " [ 0.00715891  0.02018627  0.01562194 -0.01187166 -0.01018461 -0.00015145\n",
      "   0.00194899  0.01654181  0.02198643 -0.00148443]\n",
      " [ 0.00717784  0.01943984  0.01727136 -0.01263821 -0.01088985 -0.00036111\n",
      "   0.00216512  0.01681467  0.02236251 -0.00230744]\n",
      " [ 0.0009018   0.0183262  -0.02976528  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391773 -0.00243722 -0.00350396  0.0159763 ]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069211  0.00636812  0.00174575  0.00085366 -0.00268099\n",
      "   0.00093445 -0.01318794 -0.01734735 -0.00961712]\n",
      " [ 0.00152086  0.02392225 -0.0361559   0.01552405  0.01448685  0.00510451\n",
      "  -0.00476485 -0.0021097  -0.00313318  0.01979037]\n",
      " [ 0.00715898  0.02018646  0.01562209 -0.01187177 -0.01018471 -0.00015146\n",
      "   0.00194901  0.01654197  0.02198664 -0.00148306]\n",
      " [ 0.00717789  0.01943997  0.01727147 -0.01263829 -0.01088992 -0.00036111\n",
      "   0.00216514  0.01681477  0.02236265 -0.00230602]\n",
      " [ 0.00090181  0.01832623 -0.02976525  0.01301154  0.01210215  0.00411023\n",
      "  -0.00391773 -0.00243719 -0.00350392  0.01597567]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069205  0.006368    0.0017458   0.00085371 -0.00268097\n",
      "   0.00093444 -0.01318795 -0.01734737 -0.00961797]\n",
      " [ 0.00152089  0.02392267 -0.03615654  0.01552432  0.01448711  0.0051046\n",
      "  -0.00476493 -0.00210974 -0.00313324  0.01979403]\n",
      " [ 0.007159    0.02018682  0.01562157 -0.01187154 -0.0101845  -0.00015138\n",
      "   0.00194894  0.01654194  0.0219866  -0.00148382]\n",
      " [ 0.00717791  0.01944024  0.01727107 -0.01263812 -0.01088976 -0.00036105\n",
      "   0.00216508  0.01681475  0.02236262 -0.002307  ]\n",
      " [ 0.00090182  0.0183263  -0.02976536  0.01301158  0.01210219  0.00411025\n",
      "  -0.00391774 -0.0024372  -0.00350394  0.01597844]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704842 -0.03069213  0.00636802  0.00174581  0.00085371 -0.00268098\n",
      "   0.00093444 -0.01318799 -0.01734741 -0.00961673]\n",
      " [ 0.00152074  0.02392205 -0.03615643  0.01552437  0.01448713  0.00510455\n",
      "  -0.00476492 -0.00211001 -0.00313359  0.0197929 ]\n",
      " [ 0.00715892  0.02018645  0.01562168 -0.01187154 -0.0101845  -0.00015142\n",
      "   0.00194896  0.01654179  0.02198641 -0.00148481]\n",
      " [ 0.00717785  0.01943998  0.01727116 -0.01263812 -0.01088977 -0.00036108\n",
      "   0.0021651   0.01681466  0.02236249 -0.00230792]\n",
      " [ 0.0009018   0.01832624 -0.02976534  0.01301158  0.01210219  0.00411024\n",
      "  -0.00391774 -0.00243723 -0.00350397  0.01597769]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704839 -0.03069203  0.0063681   0.00174574  0.00085366 -0.00268098\n",
      "   0.00093445 -0.0131879  -0.0173473  -0.00961836]\n",
      " [ 0.001521    0.02392286 -0.03615601  0.015524    0.01448682  0.00510456\n",
      "  -0.00476486 -0.00210943 -0.00313282  0.01979151]\n",
      " [ 0.00715906  0.02018683  0.01562198 -0.01187177 -0.0101847  -0.00015142\n",
      "   0.00194899  0.01654211  0.02198683 -0.00148207]\n",
      " [ 0.00717794  0.01944022  0.01727137 -0.01263828 -0.0108899  -0.00036109\n",
      "   0.00216512  0.01681487  0.02236277 -0.0023051 ]\n",
      " [ 0.00090183  0.0183263  -0.02976527  0.01301154  0.01210215  0.00411024\n",
      "  -0.00391773 -0.00243717 -0.00350389  0.01597642]]\n",
      "W2 max relative error: 3.440708e-09\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069207  0.00636806  0.00174577  0.00085368 -0.00268098\n",
      "   0.00093444 -0.01318794 -0.01734735 -0.00961754]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636808  0.00174577  0.00085368 -0.00268098\n",
      "   0.00093445 -0.01318794 -0.01734735 -0.00961755]\n",
      " [ 0.00152087  0.02392245 -0.03615621  0.01552418  0.01448697  0.00510455\n",
      "  -0.00476489 -0.00210972 -0.0031332   0.0197922 ]\n",
      " [ 0.00715899  0.02018663  0.01562185 -0.01187167 -0.01018461 -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148345]\n",
      " [ 0.0071779   0.01944009  0.01727129 -0.01263821 -0.01088984 -0.00036109\n",
      "   0.00216511  0.01681477  0.02236264 -0.00230652]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069207  0.00636804  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961754]\n",
      " [ 0.00152087  0.02392246 -0.03615623  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210973 -0.00313321  0.01979221]\n",
      " [ 0.00715899  0.02018665  0.01562181 -0.01187165 -0.01018459 -0.00015142\n",
      "   0.00194897  0.01654195  0.02198662 -0.00148343]\n",
      " [ 0.0071779   0.01944011  0.01727125 -0.01263819 -0.01088983 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.0023065 ]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069208  0.00636805  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961754]\n",
      " [ 0.00152087  0.02392246 -0.03615623  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210973 -0.00313321  0.01979221]\n",
      " [ 0.00715899  0.02018664  0.01562182 -0.01187165 -0.0101846  -0.00015142\n",
      "   0.00194897  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727126 -0.0126382  -0.01088983 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636807  0.00174577  0.00085368 -0.00268098\n",
      "   0.00093445 -0.01318794 -0.01734735 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615621  0.01552418  0.01448697  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.0031332   0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562184 -0.01187166 -0.01018461 -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727128 -0.01263821 -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681477  0.02236264 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069208  0.00636805  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961754]\n",
      " [ 0.00152087  0.02392246 -0.03615623  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210973 -0.00313321  0.01979221]\n",
      " [ 0.00715899  0.02018664  0.01562182 -0.01187165 -0.0101846  -0.00015142\n",
      "   0.00194897  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727126 -0.0126382  -0.01088983 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636807  0.00174577  0.00085368 -0.00268098\n",
      "   0.00093445 -0.01318794 -0.01734735 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615621  0.01552418  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.0031332   0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562184 -0.01187166 -0.01018461 -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.01263821 -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681477  0.02236264 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090182  0.01832628 -0.0297653   0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.00243719 -0.00350392  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832626 -0.02976531  0.01301156  0.01210218  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350394  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152088  0.02392247 -0.03615622  0.01552418  0.01448697  0.00510456\n",
      "  -0.00476489 -0.00210971 -0.0031332   0.01979221]\n",
      " [ 0.00715899  0.02018665  0.01562183 -0.01187166 -0.01018461 -0.00015142\n",
      "   0.00194898  0.01654196  0.02198663 -0.00148344]\n",
      " [ 0.0071779   0.01944012  0.01727127 -0.01263821 -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681477  0.02236265 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392244 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210973 -0.00313322  0.0197922 ]\n",
      " [ 0.00715898  0.02018663  0.01562183 -0.01187165 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654194  0.02198661 -0.00148344]\n",
      " [ 0.0071779   0.01944009  0.01727126 -0.0126382  -0.01088983 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236262 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069207  0.00636805  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318794 -0.01734736 -0.00961754]\n",
      " [ 0.00152087  0.02392247 -0.03615623  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.01979221]\n",
      " [ 0.00715899  0.02018665  0.01562182 -0.01187165 -0.0101846  -0.00015142\n",
      "   0.00194897  0.01654195  0.02198662 -0.00148343]\n",
      " [ 0.0071779   0.01944011  0.01727126 -0.0126382  -0.01088983 -0.00036108\n",
      "   0.00216511  0.01681477  0.02236264 -0.0023065 ]\n",
      " [ 0.00090181  0.01832628 -0.02976532  0.01301156  0.01210218  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597706]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069209  0.00636807  0.00174577  0.00085368 -0.00268098\n",
      "   0.00093445 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392245 -0.03615621  0.01552418  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018663  0.01562184 -0.01187166 -0.01018461 -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.01944009  0.01727128 -0.01263821 -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230652]\n",
      " [ 0.00090181  0.01832626 -0.0297653   0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "b1 max relative error: 1.000000e+00\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704838 -0.03069198  0.00636807  0.00174575  0.00085367 -0.00268097\n",
      "   0.00093445 -0.01318789 -0.01734728 -0.00961753]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704843 -0.03069218  0.00636805  0.0017458   0.0008537  -0.00268099\n",
      "   0.00093444 -0.013188   -0.01734743 -0.00961756]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704839 -0.03069218  0.00636835  0.00174563  0.00085356 -0.00268101\n",
      "   0.00093448 -0.01318788 -0.01734727 -0.00961768]\n",
      " [ 0.00152088  0.02392241 -0.0361561   0.01552413  0.01448693  0.00510454\n",
      "  -0.00476487 -0.0021097  -0.00313318  0.01979215]\n",
      " [ 0.00715899  0.02018661  0.01562189 -0.01187168 -0.01018463 -0.00015143\n",
      "   0.00194898  0.01654196  0.02198663 -0.00148347]\n",
      " [ 0.0071779   0.01944014  0.0172712  -0.01263817 -0.01088981 -0.00036107\n",
      "   0.0021651   0.01681476  0.02236262 -0.00230648]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704842 -0.03069198  0.00636777  0.00174592  0.00085381 -0.00268094\n",
      "   0.00093441 -0.01318801 -0.01734745 -0.00961741]\n",
      " [ 0.00152087  0.02392251 -0.03615634  0.01552424  0.01448703  0.00510457\n",
      "  -0.00476491 -0.00210975 -0.00313324  0.01979226]\n",
      " [ 0.00715899  0.02018667  0.01562177 -0.01187163 -0.01018458 -0.00015141\n",
      "   0.00194897  0.01654194  0.02198661 -0.00148341]\n",
      " [ 0.0071779   0.01944007  0.01727133 -0.01263823 -0.01088986 -0.00036109\n",
      "   0.00216512  0.01681477  0.02236265 -0.00230654]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704843 -0.0306921   0.00636792  0.00174585  0.00085376 -0.00268097\n",
      "   0.00093443 -0.01318801 -0.01734745 -0.00961749]\n",
      " [ 0.00152086  0.02392244 -0.03615628  0.01552422  0.01448701  0.00510456\n",
      "  -0.0047649  -0.00210975 -0.00313325  0.01979222]\n",
      " [ 0.00715898  0.02018664  0.0156218  -0.01187164 -0.01018459 -0.00015142\n",
      "   0.00194897  0.01654194  0.02198661 -0.00148343]\n",
      " [ 0.0071779   0.0194401   0.0172713  -0.01263822 -0.01088985 -0.00036109\n",
      "   0.00216511  0.01681477  0.02236265 -0.00230652]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704838 -0.03069206  0.0063682   0.0017457   0.00085361 -0.00268099\n",
      "   0.00093446 -0.01318788 -0.01734727 -0.0096176 ]\n",
      " [ 0.00152089  0.02392247 -0.03615616  0.01552415  0.01448695  0.00510455\n",
      "  -0.00476488 -0.00210969 -0.00313317  0.01979219]\n",
      " [ 0.00715899  0.02018664  0.01562186 -0.01187167 -0.01018462 -0.00015142\n",
      "   0.00194898  0.01654196  0.02198663 -0.00148345]\n",
      " [ 0.0071779   0.0194401   0.01727124 -0.01263819 -0.01088982 -0.00036108\n",
      "   0.00216511  0.01681475  0.02236262 -0.0023065 ]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704842 -0.03069209  0.00636793  0.00174585  0.00085375 -0.00268097\n",
      "   0.00093443 -0.013188   -0.01734743 -0.0096175 ]\n",
      " [ 0.00152086  0.02392245 -0.03615627  0.01552422  0.01448701  0.00510456\n",
      "  -0.0047649  -0.00210975 -0.00313324  0.01979222]\n",
      " [ 0.00715898  0.02018664  0.0156218  -0.01187164 -0.01018459 -0.00015142\n",
      "   0.00194897  0.01654194  0.02198661 -0.00148343]\n",
      " [ 0.0071779   0.0194401   0.01727129 -0.01263822 -0.01088985 -0.00036109\n",
      "   0.00216511  0.01681477  0.02236265 -0.00230652]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704839 -0.03069207  0.00636819  0.0017457   0.00085362 -0.00268099\n",
      "   0.00093446 -0.01318789 -0.01734728 -0.00961759]\n",
      " [ 0.00152088  0.02392247 -0.03615617  0.01552416  0.01448695  0.00510455\n",
      "  -0.00476488 -0.0021097  -0.00313317  0.01979219]\n",
      " [ 0.00715899  0.02018664  0.01562186 -0.01187167 -0.01018461 -0.00015142\n",
      "   0.00194898  0.01654196  0.02198663 -0.00148345]\n",
      " [ 0.0071779   0.01944011  0.01727124 -0.01263819 -0.01088982 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236262 -0.0023065 ]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832625 -0.02976531  0.01301157  0.01210218  0.00411024\n",
      "  -0.00391774 -0.00243721 -0.00350394  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090182  0.01832628 -0.0297653   0.01301155  0.01210217  0.00411024\n",
      "  -0.00391774 -0.00243719 -0.00350391  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152091  0.0239226  -0.03615619  0.01552414  0.01448694  0.00510456\n",
      "  -0.00476489 -0.00210964 -0.00313309  0.01979223]\n",
      " [ 0.007159    0.02018669  0.01562184 -0.01187167 -0.01018461 -0.00015142\n",
      "   0.00194898  0.01654198  0.02198666 -0.00148343]\n",
      " [ 0.00717789  0.01944006  0.01727125 -0.01263819 -0.01088982 -0.00036108\n",
      "   0.00216511  0.01681474  0.0223626  -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152083  0.02392231 -0.03615625  0.01552423  0.01448701  0.00510455\n",
      "  -0.00476489 -0.00210981 -0.00313332  0.01979218]\n",
      " [ 0.00715897  0.02018659  0.01562182 -0.01187164 -0.01018459 -0.00015142\n",
      "   0.00194897  0.01654192  0.02198658 -0.00148344]\n",
      " [ 0.00717791  0.01944015  0.01727128 -0.01263822 -0.01088985 -0.00036108\n",
      "   0.00216511  0.01681479  0.02236267 -0.0023065 ]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704839 -0.03069194  0.00636792  0.00174583  0.00085373 -0.00268096\n",
      "   0.00093443 -0.01318793 -0.01734734 -0.00961746]\n",
      " [ 0.00152089  0.02392253 -0.03615628  0.01552421  0.014487    0.00510457\n",
      "  -0.0047649  -0.00210971 -0.00313319  0.01979225]\n",
      " [ 0.00715899  0.02018667  0.0156218  -0.01187165 -0.01018459 -0.00015141\n",
      "   0.00194897  0.01654196  0.02198663 -0.00148342]\n",
      " [ 0.00717789  0.01944007  0.0172713  -0.01263822 -0.01088985 -0.00036109\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230653]\n",
      " [ 0.00090181  0.01832625 -0.02976529  0.01301155  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597704]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704842 -0.03069222  0.0063682   0.00174572  0.00085364 -0.002681\n",
      "   0.00093446 -0.01318796 -0.01734738 -0.00961763]\n",
      " [ 0.00152086  0.02392238 -0.03615616  0.01552417  0.01448696  0.00510455\n",
      "  -0.00476488 -0.00210974 -0.00313323  0.01979216]\n",
      " [ 0.00715898  0.02018661  0.01562186 -0.01187167 -0.01018461 -0.00015142\n",
      "   0.00194898  0.01654195  0.02198661 -0.00148346]\n",
      " [ 0.0071779   0.01944014  0.01727123 -0.01263819 -0.01088982 -0.00036108\n",
      "   0.0021651   0.01681477  0.02236264 -0.00230649]\n",
      " [ 0.00090182  0.01832629 -0.02976532  0.01301157  0.01210218  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597706]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069212  0.00636805  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318797 -0.01734739 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704839 -0.03069204  0.00636806  0.00174577  0.00085368 -0.00268098\n",
      "   0.00093445 -0.01318792 -0.01734733 -0.00961754]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069204  0.00636795  0.00174583  0.00085373 -0.00268097\n",
      "   0.00093443 -0.01318797 -0.01734739 -0.00961749]\n",
      " [ 0.00152086  0.02392258 -0.03615655  0.01552434  0.01448712  0.0051046\n",
      "  -0.00476493 -0.00210979 -0.0031333   0.01979236]\n",
      " [ 0.00715899  0.02018666  0.01562178 -0.01187164 -0.01018458 -0.00015141\n",
      "   0.00194897  0.01654194  0.02198661 -0.00148341]\n",
      " [ 0.0071779   0.01944014  0.01727119 -0.01263817 -0.0108898  -0.00036107\n",
      "   0.0021651   0.01681475  0.02236262 -0.00230647]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069212  0.00636817  0.00174572  0.00085364 -0.00268099\n",
      "   0.00093446 -0.01318792 -0.01734732 -0.0096176 ]\n",
      " [ 0.00152088  0.02392233 -0.0361559   0.01552403  0.01448684  0.00510452\n",
      "  -0.00476485 -0.00210966 -0.00313312  0.01979205]\n",
      " [ 0.00715899  0.02018662  0.01562188 -0.01187168 -0.01018462 -0.00015142\n",
      "   0.00194898  0.01654196  0.02198663 -0.00148346]\n",
      " [ 0.0071779   0.01944006  0.01727134 -0.01263824 -0.01088987 -0.00036109\n",
      "   0.00216512  0.01681477  0.02236265 -0.00230655]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069207  0.00636811  0.00174575  0.00085366 -0.00268098\n",
      "   0.00093445 -0.01318792 -0.01734732 -0.00961756]\n",
      " [ 0.0015209   0.0239225  -0.03615607  0.01552409  0.0144869   0.00510454\n",
      "  -0.00476487 -0.00210964 -0.0031331   0.01979215]\n",
      " [ 0.00715899  0.02018664  0.01562185 -0.01187167 -0.01018461 -0.00015142\n",
      "   0.00194898  0.01654196  0.02198663 -0.00148345]\n",
      " [ 0.0071779   0.0194401   0.0172713  -0.01263822 -0.01088985 -0.00036109\n",
      "   0.00216511  0.01681478  0.02236265 -0.00230652]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069209  0.00636801  0.00174581  0.00085371 -0.00268098\n",
      "   0.00093444 -0.01318797 -0.01734739 -0.00961753]\n",
      " [ 0.00152084  0.02392241 -0.03615637  0.01552428  0.01448706  0.00510457\n",
      "  -0.00476491 -0.00210981 -0.00313332  0.01979226]\n",
      " [ 0.00715898  0.02018664  0.01562181 -0.01187165 -0.01018459 -0.00015142\n",
      "   0.00194897  0.01654194  0.02198661 -0.00148343]\n",
      " [ 0.0071779   0.01944011  0.01727123 -0.01263818 -0.01088982 -0.00036108\n",
      "   0.0021651   0.01681475  0.02236262 -0.00230649]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636811  0.00174575  0.00085366 -0.00268098\n",
      "   0.00093445 -0.01318792 -0.01734733 -0.00961756]\n",
      " [ 0.0015209   0.02392248 -0.03615608  0.01552411  0.01448691  0.00510454\n",
      "  -0.00476487 -0.00210965 -0.00313312  0.01979215]\n",
      " [ 0.00715899  0.02018664  0.01562185 -0.01187167 -0.01018461 -0.00015142\n",
      "   0.00194898  0.01654196  0.02198663 -0.00148345]\n",
      " [ 0.0071779   0.0194401   0.0172713  -0.01263822 -0.01088985 -0.00036109\n",
      "   0.00216511  0.01681477  0.02236265 -0.00230652]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069208  0.00636801  0.0017458   0.00085371 -0.00268098\n",
      "   0.00093444 -0.01318797 -0.01734739 -0.00961753]\n",
      " [ 0.00152085  0.02392243 -0.03615636  0.01552427  0.01448705  0.00510457\n",
      "  -0.00476491 -0.00210979 -0.0031333   0.01979225]\n",
      " [ 0.00715898  0.02018664  0.01562181 -0.01187165 -0.01018459 -0.00015142\n",
      "   0.00194897  0.01654194  0.02198661 -0.00148343]\n",
      " [ 0.0071779   0.01944011  0.01727123 -0.01263819 -0.01088982 -0.00036108\n",
      "   0.0021651   0.01681475  0.02236262 -0.0023065 ]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090179  0.01832618 -0.02976534  0.01301159  0.0121022   0.00411024\n",
      "  -0.00391774 -0.00243725 -0.003504    0.01597704]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090184  0.01832635 -0.02976528  0.01301153  0.01210215  0.00411024\n",
      "  -0.00391773 -0.00243714 -0.00350385  0.01597706]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152076  0.02392207 -0.03615631  0.0155243   0.01448707  0.00510454\n",
      "  -0.0047649  -0.00210995 -0.00313352  0.01979215]\n",
      " [ 0.00715898  0.0201866   0.01562182 -0.01187165 -0.01018459 -0.00015142\n",
      "   0.00194897  0.01654193  0.02198659 -0.00148344]\n",
      " [ 0.00717788  0.01944005  0.01727125 -0.01263819 -0.01088982 -0.00036109\n",
      "   0.00216511  0.01681473  0.02236259 -0.00230652]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152098  0.02392284 -0.03615613  0.01552407  0.01448689  0.00510457\n",
      "  -0.00476488 -0.00210949 -0.0031329   0.01979226]\n",
      " [ 0.007159    0.02018668  0.01562184 -0.01187167 -0.01018461 -0.00015142\n",
      "   0.00194898  0.01654197  0.02198665 -0.00148343]\n",
      " [ 0.00717791  0.01944015  0.01727128 -0.01263822 -0.01088985 -0.00036108\n",
      "   0.00216511  0.0168148   0.02236268 -0.0023065 ]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069213  0.00636811  0.00174576  0.00085367 -0.00268099\n",
      "   0.00093445 -0.01318795 -0.01734737 -0.00961758]\n",
      " [ 0.00152084  0.02392225 -0.03615606  0.01552414  0.01448693  0.00510453\n",
      "  -0.00476487 -0.00210977 -0.00313326  0.0197921 ]\n",
      " [ 0.00715898  0.02018661  0.01562185 -0.01187167 -0.01018461 -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148345]\n",
      " [ 0.00717789  0.01944006  0.01727131 -0.01263822 -0.01088985 -0.00036109\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230653]\n",
      " [ 0.0009018   0.01832618 -0.02976521  0.01301152  0.01210214  0.00411023\n",
      "  -0.00391772 -0.00243721 -0.00350394  0.01597699]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069203  0.00636801  0.00174579  0.0008537  -0.00268097\n",
      "   0.00093444 -0.01318794 -0.01734735 -0.00961751]\n",
      " [ 0.00152091  0.02392266 -0.03615638  0.01552424  0.01448703  0.00510459\n",
      "  -0.00476491 -0.00210968 -0.00313315  0.01979231]\n",
      " [ 0.00715899  0.02018667  0.01562181 -0.01187165 -0.01018459 -0.00015141\n",
      "   0.00194897  0.01654196  0.02198662 -0.00148342]\n",
      " [ 0.0071779   0.01944014  0.01727123 -0.01263819 -0.01088982 -0.00036108\n",
      "   0.0021651   0.01681477  0.02236264 -0.00230648]\n",
      " [ 0.00090182  0.01832636 -0.0297654   0.0130116   0.01210221  0.00411026\n",
      "  -0.00391775 -0.00243719 -0.00350392  0.01597711]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069211  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318796 -0.01734738 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069205  0.00636806  0.00174577  0.00085368 -0.00268098\n",
      "   0.00093445 -0.01318793 -0.01734733 -0.00961754]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069205  0.00636796  0.00174582  0.00085373 -0.00268097\n",
      "   0.00093443 -0.01318797 -0.01734739 -0.0096175 ]\n",
      " [ 0.00152088  0.02392236 -0.03615597  0.01552407  0.01448687  0.00510453\n",
      "  -0.00476486 -0.00210967 -0.00313314  0.01979209]\n",
      " [ 0.00715899  0.0201865   0.01562211 -0.01187178 -0.01018472 -0.00015145\n",
      "   0.00194901  0.01654199  0.02198668 -0.00148358]\n",
      " [ 0.0071779   0.01943998  0.0172715  -0.01263831 -0.01088993 -0.00036111\n",
      "   0.00216514  0.01681479  0.02236268 -0.00230663]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069211  0.00636815  0.00174573  0.00085364 -0.00268099\n",
      "   0.00093446 -0.01318792 -0.01734733 -0.00961759]\n",
      " [ 0.00152087  0.02392255 -0.03615647  0.0155243   0.01448709  0.00510459\n",
      "  -0.00476492 -0.00210977 -0.00313328  0.01979232]\n",
      " [ 0.00715899  0.02018677  0.01562155 -0.01187153 -0.01018449 -0.00015138\n",
      "   0.00194894  0.01654191  0.02198656 -0.0014833 ]\n",
      " [ 0.0071779   0.01944022  0.01727104 -0.0126381  -0.01088974 -0.00036105\n",
      "   0.00216508  0.01681473  0.02236259 -0.00230639]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069207  0.0063681   0.00174575  0.00085366 -0.00268098\n",
      "   0.00093445 -0.01318792 -0.01734733 -0.00961756]\n",
      " [ 0.00152085  0.02392242 -0.03615634  0.01552426  0.01448704  0.00510457\n",
      "  -0.00476491 -0.00210979 -0.00313329  0.01979224]\n",
      " [ 0.00715897  0.02018664  0.0156217  -0.01187159 -0.01018454 -0.00015141\n",
      "   0.00194896  0.0165419   0.02198655 -0.00148339]\n",
      " [ 0.00717789  0.01944011  0.01727116 -0.01263815 -0.01088979 -0.00036107\n",
      "   0.0021651   0.01681473  0.02236259 -0.00230647]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069208  0.00636801  0.0017458   0.00085371 -0.00268098\n",
      "   0.00093444 -0.01318797 -0.01734739 -0.00961753]\n",
      " [ 0.0015209   0.02392249 -0.0361561   0.01552412  0.01448692  0.00510455\n",
      "  -0.00476488 -0.00210966 -0.00313312  0.01979217]\n",
      " [ 0.007159    0.02018664  0.01562196 -0.01187172 -0.01018466 -0.00015143\n",
      "   0.00194899  0.016542    0.02198669 -0.00148349]\n",
      " [ 0.00717791  0.01944009  0.01727137 -0.01263826 -0.01088989 -0.00036109\n",
      "   0.00216512  0.0168148   0.02236268 -0.00230655]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.0063681   0.00174575  0.00085367 -0.00268098\n",
      "   0.00093445 -0.01318793 -0.01734733 -0.00961756]\n",
      " [ 0.00152086  0.02392244 -0.03615633  0.01552425  0.01448703  0.00510457\n",
      "  -0.0047649  -0.00210977 -0.00313328  0.01979224]\n",
      " [ 0.00715898  0.02018665  0.01562171 -0.0118716  -0.01018455 -0.00015141\n",
      "   0.00194896  0.01654191  0.02198657 -0.00148339]\n",
      " [ 0.00717789  0.01944012  0.01727117 -0.01263815 -0.01088979 -0.00036107\n",
      "   0.0021651   0.01681473  0.02236259 -0.00230647]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069208  0.00636802  0.0017458   0.00085371 -0.00268098\n",
      "   0.00093444 -0.01318796 -0.01734738 -0.00961753]\n",
      " [ 0.00152089  0.02392248 -0.03615611  0.01552412  0.01448692  0.00510455\n",
      "  -0.00476488 -0.00210967 -0.00313314  0.01979217]\n",
      " [ 0.007159    0.02018663  0.01562195 -0.01187172 -0.01018466 -0.00015143\n",
      "   0.00194899  0.01654199  0.02198667 -0.00148349]\n",
      " [ 0.00717791  0.01944008  0.01727136 -0.01263825 -0.01088988 -0.00036109\n",
      "   0.00216512  0.01681479  0.02236267 -0.00230655]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.0297653   0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.00243719 -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832626 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152096  0.02392275 -0.03615615  0.0155241   0.01448691  0.00510457\n",
      "  -0.00476488 -0.00210955 -0.00313298  0.01979225]\n",
      " [ 0.00715905  0.02018685  0.01562189 -0.01187172 -0.01018466 -0.00015141\n",
      "   0.00194898  0.01654208  0.02198679 -0.00148341]\n",
      " [ 0.00717794  0.01944026  0.01727131 -0.01263825 -0.01088988 -0.00036108\n",
      "   0.00216511  0.01681486  0.02236276 -0.00230649]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152079  0.02392217 -0.03615629  0.01552427  0.01448705  0.00510454\n",
      "  -0.0047649  -0.0021099  -0.00313344  0.01979216]\n",
      " [ 0.00715893  0.02018643  0.01562177 -0.01187159 -0.01018455 -0.00015143\n",
      "   0.00194897  0.01654182  0.02198645 -0.00148347]\n",
      " [ 0.00717785  0.01943995  0.01727123 -0.01263815 -0.0108898  -0.00036109\n",
      "   0.0021651   0.01681467  0.02236251 -0.00230653]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069212  0.0063681   0.00174576  0.00085367 -0.00268099\n",
      "   0.00093445 -0.01318795 -0.01734737 -0.00961757]\n",
      " [ 0.0015209   0.02392261 -0.03615634  0.01552422  0.01448702  0.00510458\n",
      "  -0.00476491 -0.00210969 -0.00313317  0.01979229]\n",
      " [ 0.00715901  0.02018679  0.01562169 -0.01187161 -0.01018455 -0.00015139\n",
      "   0.00194896  0.01654197  0.02198665 -0.00148335]\n",
      " [ 0.00717792  0.01944022  0.01727115 -0.01263816 -0.01088979 -0.00036106\n",
      "   0.00216509  0.01681478  0.02236265 -0.00230643]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597706]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069203  0.00636801  0.00174579  0.0008537  -0.00268097\n",
      "   0.00093444 -0.01318794 -0.01734735 -0.00961752]\n",
      " [ 0.00152085  0.0239223  -0.0361561   0.01552415  0.01448694  0.00510453\n",
      "  -0.00476487 -0.00210975 -0.00313325  0.01979212]\n",
      " [ 0.00715897  0.02018649  0.01562197 -0.01187171 -0.01018465 -0.00015144\n",
      "   0.00194899  0.01654193  0.02198659 -0.00148353]\n",
      " [ 0.00717788  0.01943998  0.01727139 -0.01263825 -0.01088988 -0.0003611\n",
      "   0.00216512  0.01681475  0.02236261 -0.00230658]\n",
      " [ 0.00090181  0.01832626 -0.0297653   0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704842 -0.03069214  0.00636805  0.00174579  0.0008537  -0.00268098\n",
      "   0.00093444 -0.01318798 -0.01734741 -0.00961756]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704839 -0.03069201  0.00636807  0.00174576  0.00085367 -0.00268098\n",
      "   0.00093445 -0.01318791 -0.01734731 -0.00961753]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704841 -0.03069201  0.00636787  0.00174587  0.00085377 -0.00268096\n",
      "   0.00093442 -0.01318799 -0.01734742 -0.00961745]\n",
      " [ 0.00152087  0.0239225  -0.03615633  0.01552424  0.01448703  0.00510457\n",
      "  -0.0047649  -0.00210974 -0.00313324  0.01979226]\n",
      " [ 0.00715899  0.02018683  0.01562144 -0.01187148 -0.01018444 -0.00015137\n",
      "   0.00194892  0.01654189  0.02198654 -0.00148324]\n",
      " [ 0.0071779   0.01944022  0.01727104 -0.0126381  -0.01088974 -0.00036105\n",
      "   0.00216508  0.01681474  0.02236259 -0.00230639]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069214  0.00636825  0.00174568  0.0008536  -0.002681\n",
      "   0.00093447 -0.0131879  -0.0173473  -0.00961764]\n",
      " [ 0.00152088  0.02392242 -0.03615611  0.01552413  0.01448693  0.00510454\n",
      "  -0.00476488 -0.0021097  -0.00313318  0.01979215]\n",
      " [ 0.00715899  0.02018645  0.01562222 -0.01187183 -0.01018477 -0.00015147\n",
      "   0.00194903  0.01654201  0.0219867  -0.00148364]\n",
      " [ 0.0071779   0.01943998  0.01727149 -0.0126383  -0.01088993 -0.00036111\n",
      "   0.00216514  0.01681479  0.02236267 -0.00230662]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704839 -0.03069206  0.00636815  0.00174572  0.00085364 -0.00268099\n",
      "   0.00093446 -0.0131879  -0.0173473  -0.00961758]\n",
      " [ 0.00152088  0.02392247 -0.03615617  0.01552416  0.01448695  0.00510455\n",
      "  -0.00476488 -0.00210969 -0.00313317  0.01979219]\n",
      " [ 0.00715901  0.02018664  0.01562201 -0.01187175 -0.01018469 -0.00015144\n",
      "   0.001949    0.01654202  0.02198671 -0.00148351]\n",
      " [ 0.00717791  0.01944009  0.01727137 -0.01263826 -0.01088988 -0.00036109\n",
      "   0.00216512  0.0168148   0.02236268 -0.00230655]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704842 -0.03069209  0.00636797  0.00174583  0.00085373 -0.00268097\n",
      "   0.00093443 -0.01318799 -0.01734742 -0.00961751]\n",
      " [ 0.00152086  0.02392244 -0.03615627  0.01552422  0.01448701  0.00510456\n",
      "  -0.0047649  -0.00210975 -0.00313325  0.01979222]\n",
      " [ 0.00715897  0.02018664  0.01562165 -0.01187156 -0.01018452 -0.0001514\n",
      "   0.00194895  0.01654188  0.02198653 -0.00148337]\n",
      " [ 0.00717789  0.01944011  0.01727117 -0.01263815 -0.01088979 -0.00036107\n",
      "   0.0021651   0.01681473  0.02236259 -0.00230647]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704839 -0.03069207  0.00636814  0.00174573  0.00085364 -0.00268099\n",
      "   0.00093446 -0.01318791 -0.01734731 -0.00961758]\n",
      " [ 0.00152088  0.02392247 -0.03615617  0.01552416  0.01448695  0.00510455\n",
      "  -0.00476488 -0.0021097  -0.00313318  0.01979219]\n",
      " [ 0.007159    0.02018662  0.01562199 -0.01187174 -0.01018468 -0.00015144\n",
      "   0.001949    0.01654201  0.0219867  -0.00148351]\n",
      " [ 0.00717791  0.01944009  0.01727136 -0.01263825 -0.01088988 -0.00036109\n",
      "   0.00216512  0.01681479  0.02236267 -0.00230655]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704842 -0.03069208  0.00636797  0.00174582  0.00085373 -0.00268097\n",
      "   0.00093443 -0.01318798 -0.01734741 -0.00961751]\n",
      " [ 0.00152087  0.02392245 -0.03615627  0.01552421  0.014487    0.00510456\n",
      "  -0.0047649  -0.00210975 -0.00313324  0.01979222]\n",
      " [ 0.00715897  0.02018666  0.01562167 -0.01187157 -0.01018452 -0.0001514\n",
      "   0.00194895  0.01654189  0.02198654 -0.00148337]\n",
      " [ 0.00717789  0.01944012  0.01727117 -0.01263816 -0.01088979 -0.00036107\n",
      "   0.0021651   0.01681474  0.0223626  -0.00230647]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.00090183  0.01832633 -0.02976529  0.01301154  0.01210216  0.00411024\n",
      "  -0.00391774 -0.00243716 -0.00350388  0.01597706]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152087  0.02392246 -0.03615622  0.01552419  0.01448698  0.00510456\n",
      "  -0.00476489 -0.00210972 -0.00313321  0.0197922 ]\n",
      " [ 0.00715899  0.02018664  0.01562183 -0.01187166 -0.0101846  -0.00015142\n",
      "   0.00194898  0.01654195  0.02198662 -0.00148344]\n",
      " [ 0.0071779   0.0194401   0.01727127 -0.0126382  -0.01088984 -0.00036108\n",
      "   0.00216511  0.01681476  0.02236263 -0.00230651]\n",
      " [ 0.0009018   0.01832621 -0.02976533  0.01301158  0.01210219  0.00411024\n",
      "  -0.00391774 -0.00243723 -0.00350398  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152084  0.02392233 -0.03615625  0.01552422  0.01448701  0.00510455\n",
      "  -0.00476489 -0.0021098  -0.00313331  0.01979219]\n",
      " [ 0.0071589   0.02018634  0.01562175 -0.01187156 -0.01018453 -0.00015143\n",
      "   0.00194897  0.01654177  0.02198638 -0.00148348]\n",
      " [ 0.00717786  0.01943995  0.01727123 -0.01263816 -0.0108898  -0.00036109\n",
      "   0.0021651   0.01681467  0.02236251 -0.00230653]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.0070484  -0.03069208  0.00636806  0.00174578  0.00085369 -0.00268098\n",
      "   0.00093444 -0.01318795 -0.01734736 -0.00961755]\n",
      " [ 0.00152091  0.02392258 -0.03615619  0.01552415  0.01448695  0.00510456\n",
      "  -0.00476489 -0.00210965 -0.00313311  0.01979222]\n",
      " [ 0.00715907  0.02018694  0.01562191 -0.01187175 -0.01018468 -0.00015141\n",
      "   0.00194899  0.01654214  0.02198686 -0.0014834 ]\n",
      " [ 0.00717794  0.01944025  0.01727131 -0.01263825 -0.01088987 -0.00036108\n",
      "   0.00216511  0.01681486  0.02236276 -0.00230649]\n",
      " [ 0.00090181  0.01832627 -0.02976531  0.01301156  0.01210217  0.00411024\n",
      "  -0.00391774 -0.0024372  -0.00350393  0.01597705]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704842 -0.03069217  0.00636815  0.00174574  0.00085365 -0.00268099\n",
      "   0.00093446 -0.01318796 -0.01734737 -0.0096176 ]\n",
      " [ 0.00152086  0.02392239 -0.03615617  0.01552417  0.01448696  0.00510455\n",
      "  -0.00476488 -0.00210974 -0.00313323  0.01979217]\n",
      " [ 0.00715896  0.02018643  0.01562203 -0.01187173 -0.01018467 -0.00015145\n",
      "   0.001949    0.01654192  0.02198658 -0.00148357]\n",
      " [ 0.00717788  0.01943998  0.01727138 -0.01263824 -0.01088988 -0.0003611\n",
      "   0.00216512  0.01681475  0.02236262 -0.00230658]\n",
      " [ 0.00090182  0.01832633 -0.02976537  0.01301158  0.0121022   0.00411025\n",
      "  -0.00391775 -0.00243719 -0.00350392  0.01597709]]\n",
      "X (5, 4)\n",
      "W1 (4, 10)\n",
      "b1 (10,)\n",
      "X@W1+b1 (5, 10)\n",
      "grads b1 [[-0.00704839 -0.03069199  0.00636797  0.00174581  0.00085372 -0.00268096\n",
      "   0.00093443 -0.01318793 -0.01734734 -0.00961749]\n",
      " [ 0.00152088  0.02392253 -0.03615627  0.0155242   0.01448699  0.00510457\n",
      "  -0.0047649  -0.00210971 -0.00313319  0.01979224]\n",
      " [ 0.00715902  0.02018685  0.01562163 -0.01187159 -0.01018453 -0.00015139\n",
      "   0.00194895  0.01654198  0.02198666 -0.00148331]\n",
      " [ 0.00717792  0.01944022  0.01727115 -0.01263816 -0.0108898  -0.00036106\n",
      "   0.00216509  0.01681478  0.02236265 -0.00230644]\n",
      " [ 0.00090181  0.01832621 -0.02976524  0.01301154  0.01210215  0.00411023\n",
      "  -0.00391773 -0.0024372  -0.00350394  0.01597701]]\n",
      "W1 max relative error: 1.000000e+00\n"
     ]
    }
   ],
   "source": [
    "from cs231n.gradient_check import eval_numerical_gradient\n",
    "\n",
    "# Use numeric gradient checking to check your implementation of the backward pass.\n",
    "# If your implementation is correct, the difference between the numeric and\n",
    "# analytic gradients should be less than 1e-8 for each of W1, W2, b1, and b2.\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.05)\n",
    "\n",
    "# these should all be less than 1e-8 or so\n",
    "for param_name in grads:\n",
    "    f = lambda W: net.loss(X, y, reg=0.05)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "To train the network we will use stochastic gradient descent (SGD), similar to the SVM and Softmax classifiers. Look at the function `TwoLayerNet.train` and fill in the missing sections to implement the training procedure. This should be very similar to the training procedure you used for the SVM and Softmax classifiers. You will also have to implement `TwoLayerNet.predict`, as the training process periodically performs prediction to keep track of accuracy over time while the network trains.\n",
    "\n",
    "Once you have implemented the method, run the code below to train a two-layer network on toy data. You should achieve a training loss less than 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = init_toy_model()\n",
    "stats = net.train(X, y, X, y,\n",
    "            learning_rate=1e-1, reg=5e-6,\n",
    "            num_iters=100, verbose=False)\n",
    "\n",
    "print('Final training loss: ', stats['loss_history'][-1])\n",
    "\n",
    "# plot the loss history\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('training loss')\n",
    "plt.title('Training Loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "Now that you have implemented a two-layer network that passes gradient checks and works on toy data, it's time to load up our favorite CIFAR-10 data so we can use it to train a classifier on a real dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.data_utils import load_CIFAR10\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "        \n",
    "    # Subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    # Reshape data to rows\n",
    "    X_train = X_train.reshape(num_training, -1)\n",
    "    X_val = X_val.reshape(num_validation, -1)\n",
    "    X_test = X_test.reshape(num_test, -1)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a network\n",
    "To train our network we will use SGD. In addition, we will adjust the learning rate with an exponential learning rate schedule as optimization proceeds; after each epoch, we will reduce the learning rate by multiplying it by a decay rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 50\n",
    "num_classes = 10\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Train the network\n",
    "stats = net.train(X_train, y_train, X_val, y_val,\n",
    "            num_iters=1000, batch_size=200,\n",
    "            learning_rate=1e-4, learning_rate_decay=0.95,\n",
    "            reg=0.25, verbose=True)\n",
    "\n",
    "# Predict on the validation set\n",
    "val_acc = (net.predict(X_val) == y_val).mean()\n",
    "print('Validation accuracy: ', val_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug the training\n",
    "With the default parameters we provided above, you should get a validation accuracy of about 0.29 on the validation set. This isn't very good.\n",
    "\n",
    "One strategy for getting insight into what's wrong is to plot the loss function and the accuracies on the training and validation sets during optimization.\n",
    "\n",
    "Another strategy is to visualize the weights that were learned in the first layer of the network. In most neural networks trained on visual data, the first layer weights typically show some visible structure when visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function and train / validation accuracies\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(stats['val_acc_history'], label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Clasification accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.vis_utils import visualize_grid\n",
    "\n",
    "# Visualize the weights of the network\n",
    "\n",
    "def show_net_weights(net):\n",
    "    W1 = net.params['W1']\n",
    "    W1 = W1.reshape(32, 32, 3, -1).transpose(3, 0, 1, 2)\n",
    "    plt.imshow(visualize_grid(W1, padding=3).astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_net_weights(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune your hyperparameters\n",
    "\n",
    "**What's wrong?**. Looking at the visualizations above, we see that the loss is decreasing more or less linearly, which seems to suggest that the learning rate may be too low. Moreover, there is no gap between the training and validation accuracy, suggesting that the model we used has low capacity, and that we should increase its size. On the other hand, with a very large model we would expect to see more overfitting, which would manifest itself as a very large gap between the training and validation accuracy.\n",
    "\n",
    "**Tuning**. Tuning the hyperparameters and developing intuition for how they affect the final performance is a large part of using Neural Networks, so we want you to get a lot of practice. Below, you should experiment with different values of the various hyperparameters, including hidden layer size, learning rate, numer of training epochs, and regularization strength. You might also consider tuning the learning rate decay, but you should be able to get good performance using the default value.\n",
    "\n",
    "**Approximate results**. You should be aim to achieve a classification accuracy of greater than 48% on the validation set. Our best network gets over 52% on the validation set.\n",
    "\n",
    "**Experiment**: You goal in this exercise is to get as good of a result on CIFAR-10 as you can, with a fully-connected Neural Network. Feel free implement your own techniques (e.g. PCA to reduce dimensionality, or adding dropout, or adding features to the solver, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = None # store the best model into this \n",
    "\n",
    "#################################################################################\n",
    "# TODO: Tune hyperparameters using the validation set. Store your best trained  #\n",
    "# model in best_net.                                                            #\n",
    "#                                                                               #\n",
    "# To help debug your network, it may help to use visualizations similar to the  #\n",
    "# ones we used above; these visualizations will have significant qualitative    #\n",
    "# differences from the ones we saw above for the poorly tuned network.          #\n",
    "#                                                                               #\n",
    "# Tweaking hyperparameters by hand can be fun, but you might find it useful to  #\n",
    "# write code to sweep through possible combinations of hyperparameters          #\n",
    "# automatically like we did on the previous exercises.                          #\n",
    "#################################################################################\n",
    "# Your code\n",
    "#################################################################################\n",
    "#                               END OF YOUR CODE                                #\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the weights of the best network\n",
    "show_net_weights(best_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on the test set\n",
    "When you are done experimenting, you should evaluate your final trained network on the test set; you should get above 48%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (best_net.predict(X_test) == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inline Question**\n",
    "\n",
    "Now that you have trained a Neural Network classifier, you may find that your testing accuracy is much lower than the training accuracy. In what ways can we decrease this gap? Select all that apply.\n",
    "1. Train on a larger dataset.\n",
    "2. Add more hidden units.\n",
    "3. Increase the regularization strength.\n",
    "4. None of the above.\n",
    "\n",
    "*Your answer*:\n",
    "\n",
    "*Your explanation:*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
